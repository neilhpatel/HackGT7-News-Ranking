{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ELwAwg-CjX",
        "outputId": "0075794c-c483-43af-e28c-ac31c46dba89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "pip install mediacloud"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediacloud in /usr/local/lib/python3.6/dist-packages (3.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from mediacloud) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->mediacloud) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->mediacloud) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->mediacloud) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->mediacloud) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpcXGfMDQ6Zt",
        "outputId": "af19079d-4445-45cf-ec39-acca8f252f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (6.0.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.2.3)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (1.1.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.6/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.1->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdS371FFHqGf"
      },
      "source": [
        "def limited_matching_stories(mc_client, q, fq):\n",
        "    \"\"\"\n",
        "    Return all the stories matching a query within Media Cloud. Page through the results automatically.\n",
        "    :param mc_client: a `mediacloud.api.MediaCloud` object instantiated with your API key already\n",
        "    :param q: your query\n",
        "    :param fq: your date range query\n",
        "    :return: a list of media cloud story items\n",
        "    \"\"\"\n",
        "    last_id = 0\n",
        "    more_stories = True\n",
        "    stories = []\n",
        "    while (len(stories) < 500 and more_stories):\n",
        "        page = mc_client.storyList(q, fq, last_processed_stories_id=last_id, rows=500, sort='processed_stories_id')\n",
        "        print(\"  got one page with {} stories\".format(len(page)))\n",
        "        if len(page) == 0:\n",
        "            more_stories = False\n",
        "        else:\n",
        "            stories += page\n",
        "            last_id = page[-1]['processed_stories_id']\n",
        "    return stories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX4hkoSreKwl"
      },
      "source": [
        "def removeQuotes(words):\n",
        "  newString = \"\"\n",
        "  inQuote = False\n",
        "  for word in words:\n",
        "    if (word[0] == '\"'):\n",
        "      inQuote = True\n",
        "    if (not inQuote):\n",
        "      newString += (word + \" \")\n",
        "    if (word[len(word) - 1] == '\"'):\n",
        "      inQuote = False\n",
        "    \n",
        "  return newString\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPY8lqPykQNX"
      },
      "source": [
        "import requests\n",
        "\n",
        "def url_parcer(url):\n",
        "  try:\n",
        "    data = []\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    article.nlp()\n",
        "    words = article.text.split()\n",
        "    print(words)\n",
        "    wordCount = len(words)\n",
        "    topicAppearances = words.count(topic) \n",
        "    numQuotes = 0\n",
        "    for word in words:\n",
        "      if (word[0] == '\"'):\n",
        "        numQuotes += 1\n",
        "    r = requests.post(\"https://api.deepai.org/api/sentiment-analysis\", data = {'text': removeQuotes(words)}, headers = {'api-key': '4a102c57-b6c1-4f44-b192-294b47e8cda2'})\n",
        "    data.append(wordCount)\n",
        "    data.append(topicAppearances)\n",
        "    data.append(numQuotes)\n",
        "    data.append(r.json()['output'])\n",
        "    return words\n",
        "  except:\n",
        "    return []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6286e0K3lfS"
      },
      "source": [
        "import mediacloud.api\n",
        "import datetime\n",
        "import csv\n",
        "import pandas\n",
        "\n",
        "mc = mediacloud.api.MediaCloud('74ebee12e7edefed3f3e684af66bf346e319bc117668b02ceafeca2cfc554bfd')\n",
        "startDate = datetime.date(2020, 10, 15)\n",
        "endDate = datetime.date(2020, 10, 17)\n",
        "date_range_2019 = mc.dates_as_query_clause(startDate, endDate)\n",
        "topic = input(\"Enter a topic: \")\n",
        "uk_query = '\"' + topic + '\" and tags_id_stories:8878466'\n",
        "#print(uk_query)\n",
        "res = mc.storyCount(uk_query, date_range_2019)\n",
        "all_stories = limited_matching_stories(mc, uk_query, date_range_2019)\n",
        "#print(all_stories)\n",
        "#print(res)#['count'])\n",
        "\n",
        "import mediacloud.tags\n",
        "for s in all_stories:\n",
        "    # see the \"language\" notebook for more details on themes\n",
        "    theme_tag_names = ','.join([t['tag'] for t in s['story_tags'] if t['tag_sets_id'] == mediacloud.tags.TAG_SET_NYT_THEMES])\n",
        "    s['themes'] = theme_tag_names\n",
        "# now write the CSV\n",
        "#import csv\n",
        "fieldnames = ['stories_id', 'publish_date', 'title', 'url', 'language', 'ap_syndicated', 'themes', 'media_id', 'media_name', 'media_url']\n",
        "with open('story-list.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')\n",
        "    writer.writeheader()\n",
        "    for s in all_stories:\n",
        "        writer.writerow(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tam-jf1GEajJ"
      },
      "source": [
        "\"brexit\" and tags_id_stories:8878466 , 662194 results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcKuqIjNRbBc",
        "outputId": "dc4b4e34-0316-48b9-bd26-e4a607c8dd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import newspaper\n",
        "from newspaper import Article\n",
        "from newspaper import fulltext\n",
        "import nltk\n",
        "import requests\n",
        "import csv\n",
        "#nltk.download('punkt')\n",
        "\n",
        "urls = []\n",
        "dates = []\n",
        "\n",
        "with open(\"story-list.csv\") as csv_file:\n",
        "  csv_reader = csv.reader(csv_file, delimiter = ',')\n",
        "  for r in csv_reader:\n",
        "    if r[3] not in urls: # Eliminates repeats\n",
        "      urls.append(r[3])\n",
        "      dates.append(r[1])\n",
        "urls = urls[1:]\n",
        "print(topic)\n",
        "print(len(urls))\n",
        "url_data = {}\n",
        "for url in urls:\n",
        "  url_data[url] = url_parcer(url)\n",
        "print(url_data)\n",
        "print(\"done\")\n",
        "\n",
        "#print(urls)\n",
        "\n",
        "#a = Article(urls[1])\n",
        "\n",
        "#a.download()\n",
        "#a.parse()\n",
        "#a.nlp()\n",
        "\n",
        "#html = requests.get(\"https://www.dailystar.co.uk/news/latest-news/biker-mum-dies-suddenly-heart-22858155\").text\n",
        "#text = fulltext(html)\n",
        "#print(text)\n",
        "\n",
        "#print(\"Keywords:\", a.keywords)\n",
        "#print(\"Authors:\", a.authors)\n",
        "\n",
        "#print(a.title)\n",
        "#print(a.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elmo\n",
            "5\n",
            "{'https://nationalinterest.org/blog/reboot/wwii-what-was-it-parachute-france-d-day-170697': [], 'https://www.dailystar.co.uk/news/latest-news/biker-mum-dies-suddenly-heart-22858155': [], 'https://muppet.fandom.com/wiki/Episode_4215?diff=1333212&oldid=1331667': [], 'https://muppet.fandom.com/wiki/Sandbox:Sesame_Street_Season_19_Segments?diff=1333398&oldid=1310238': [], 'https://muppet.fandom.com/wiki/Ludwig_van_Beethoven?diff=1333473&oldid=1301873': []}\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkQwGdXsisV2"
      },
      "source": [
        "ultimateMeanVibe = 0\n",
        "for data in url_data:\n",
        "  vibeCount = 0\n",
        "  print(url_data)\n",
        "  vibeCount += url_data[data][3].count('Verynegative') * 1\n",
        "  vibeCount += url_data[data][3].count('Negative') * 2\n",
        "  vibeCount += url_data[data][3].count('Neutral') * 3\n",
        "  vibeCount += url_data[data][3].count('Positive') * 4\n",
        "  vibeCount += url_data[data][3].count('Verypositive') * 5\n",
        "  ultimateMeanVibe += (vibeCount / len(url_data[data][3]))\n",
        "  vibeCount /= len(url_data[data][3])\n",
        "  vibeCount -= 3 # centers data about 0\n",
        "  url_data[data].append(vibeCount)\n",
        "\n",
        "\n",
        "ultimateMeanVibe /= len(url_data)\n",
        "ultimateMeanVibe -= 3\n",
        "penalties = {}\n",
        "meanVibeWeight = 3 # weight to change over time\n",
        "for data in url_data:\n",
        "  penalties[data] = (abs(url_data[data][4] - ultimateMeanVibe)) * meanVibeWeight # data piece will be anywhere from 0 to 18 penalty, where it normally does not exceed 9\n",
        "\n",
        "print(dates[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnT3DTR9lOAy",
        "outputId": "b7a6ab25-6234-4256-eb3e-39b77922f5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}